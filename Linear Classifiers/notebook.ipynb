{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"a7afc3d421b64d9080dfc1daf9a8fbea","deepnote_cell_type":"markdown","tags":[]},"source":["# Improving Linear Classifiers"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"9d52456c642f4f2eafa872d2b30ea5e0","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":3158,"execution_start":1620634449745,"source_hash":"b56db82d","tags":[]},"outputs":[],"source":["import time\n","import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import Normalizer\n","from sklearn.pipeline import make_pipeline\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.base import BaseEstimator"]},{"cell_type":"markdown","metadata":{"cell_id":"a3d60ab9080643838fc9d68918bfade3","deepnote_cell_type":"markdown","tags":[]},"source":["## Processing the data "]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"2719e2dd685c47c5bd1ceb505e66f390","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":35,"execution_start":1620634452921,"source_hash":"74b9c3c3","tags":[]},"outputs":[],"source":["def read_data(corpus_file, test_size=0.2, random_state=0):\n","    X = []\n","    Y = []\n","    with open(corpus_file, encoding=\"utf-8\") as f:\n","        for line in f:\n","            _, y, _, x = line.split(maxsplit=3)\n","            X.append(x.strip())\n","            Y.append(y)\n","    return train_test_split(\n","        X, Y, test_size=test_size, random_state=random_state\n","    )\n","\n","def create_pipeline(clf, select_k_best=1000):\n","    return make_pipeline(\n","        TfidfVectorizer(),\n","        SelectKBest(k=select_k_best),\n","        Normalizer(),        \n","        clf\n","    )\n","\n","def measure_pipeline(pipeline):\n","    # Train the classifier.\n","    t0 = time.time()\n","    pipeline.fit(Xtrain, Ytrain)\n","    t1 = time.time()\n","    print(\"Training time: {:.2f} sec.\".format(t1 - t0))\n","\n","    # Evaluate on the test set.\n","    Yguess = pipeline.predict(Xtest)\n","    print(\"Accuracy: {:.4f}.\".format(accuracy_score(Ytest, Yguess)))"]},{"cell_type":"markdown","metadata":{"cell_id":"357d91d1207944258c463c633c97de8b","deepnote_cell_type":"markdown","tags":[]},"source":["# LinearClassifier baseclass\n","### This is the class provided with the perceptron in the zipped file linked in the introduction"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"8dcd17e350bc4026a55a4843dcc9b948","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":31,"execution_start":1620634452967,"source_hash":"7204b284","tags":[]},"outputs":[],"source":["class LinearClassifier(BaseEstimator):    \n","    def decision_function(self, X):        \n","        return X.dot(self.w)\n","\n","    def predict(self, X):        \n","        # First compute the output scores\n","        scores = self.decision_function(X)\n","\n","        # Select the positive or negative class label, depending on whether\n","        # the score was positive or negative.\n","        out = np.select([scores >= 0.0, scores < 0.0],\n","                        [self.positive_class,\n","                         self.negative_class])\n","        return out\n","\n","    def find_classes(self, Y):  \n","        classes = sorted(set(Y))\n","        if len(classes) != 2:\n","            raise Exception(\"this does not seem to be a 2-class problem\")\n","        self.positive_class = classes[1]\n","        self.negative_class = classes[0]\n","\n","    def encode_outputs(self, Y):       \n","        return np.array([1 if y == self.positive_class else -1 for y in Y])\n","\n"]},{"cell_type":"markdown","metadata":{"cell_id":"36bfb03d9a6d47e48c5c6ff1d9fed033","deepnote_cell_type":"markdown","tags":[]},"source":["# LinearSVC and LogisticRegression\n","### They follow the perceptron structure with some minor changes\n","\n","We initialize t=1 to avoid the division by zero corner case during the first iteration. However this only applies to the models which use the rescaling factor a, because we use (1/a) during the calculation of the loss function, but to be able to benchmark every model with each other we stay consistent."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"2f0293e79b4d4d4b91512ad0272980e1","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":17,"execution_start":1620634453014,"source_hash":"40ea96a","tags":[]},"outputs":[],"source":["class LinearSVC(LinearClassifier):\n","    def __init__(self, n_iter=20):\n","        self.n_iter = n_iter\n","\n","    def fit(self, X, Y):\n","        self.find_classes(Y)\n","        encoded_Y = self.encode_outputs(Y)\n","\n","        if not isinstance(X, np.ndarray):\n","            X = X.toarray()\n","\n","        n_instances, n_features = X.shape\n","        self.w = np.zeros(n_features)\n","        regularization = 1 / n_features        \n","\n","        t = 1\n","        for i in range(self.n_iter):\n","            for x, y in zip(X, encoded_Y):\n","                t += 1\n","                learning_rate = 1 / (t * regularization)\n","                score = x.dot(self.w)\n","\n","                self.w = (1 - learning_rate * regularization) * self.w\n","\n","                if y * score < 1:\n","                    self.w += (learning_rate * y) * x"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"6992f2bf9f4e44a2a0a3cec82eb09d30","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":25,"execution_start":1620634453040,"source_hash":"13b91c7e","tags":[]},"outputs":[],"source":["class LogisticRegression(LinearClassifier):\n","    def __init__(self, n_iter=20):\n","        self.n_iter = n_iter\n","\n","    def fit(self, X, Y):\n","        self.find_classes(Y)\n","        encoded_Y = self.encode_outputs(Y)\n","\n","        if not isinstance(X, np.ndarray):\n","            X = X.toarray()\n","\n","        n_instances, n_features = X.shape\n","        self.w = np.zeros(n_features)\n","        regularization = 1 / n_features\n","        \n","        t = 1\n","        for i in range(self.n_iter):\n","            for x, y in zip(X, encoded_Y):\n","                t += 1\n","                learning_rate = 1 / (t * regularization)                           \n","\n","                self.w = (1 - learning_rate * regularization) * self.w\n","\n","                self.w += (y * x) / (1 + np.exp(y * (x.dot(self.w))))            \n"]},{"cell_type":"markdown","metadata":{"cell_id":"a18ccd644a544dbf9c3212623aedd839","deepnote_cell_type":"markdown","tags":[]},"source":["# Evaluation of LinearSVC and LogisticRegression\n","\n","These are the times we compare the optimized classifiers with"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"06c6f109235f4ca0b5265f624eb4c0f5","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":16490,"execution_start":1620634453071,"source_hash":"bfeddcf8","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["LinearSVC\n","Training time: 7.09 sec.\n","Accuracy: 0.8242.\n","\n","LogisticRegression\n","Training time: 8.28 sec.\n","Accuracy: 0.8212.\n"]}],"source":["# Read and split two train and test set\n","Xtrain, Xtest, Ytrain, Ytest = read_data(\"all_sentiment_shuffled.txt\")\n","\n","# Set up the preprocessing steps and the classifier.\n","pipeSVC = create_pipeline(LinearSVC())\n","pipeLR = create_pipeline(LogisticRegression())\n","\n","print(\"LinearSVC\")\n","measure_pipeline(pipeSVC)\n","print(\"\\nLogisticRegression\")\n","measure_pipeline(pipeLR)"]},{"cell_type":"markdown","metadata":{"cell_id":"177002e7ac044f5487aa719b52026ef7","deepnote_cell_type":"markdown","tags":[]},"source":["### Here the same classifiers are run, but using stochastic gradient descent. This saves quite a lot of time and preserves accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"67fed897d4d1416c9cde4dd39cf5ad15","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":6,"execution_start":1620634469570,"source_hash":"fab4daaa","tags":[]},"outputs":[],"source":["class BatchLogisticRegression(LinearClassifier):\n","    def __init__(self, n_iter=20, frac=0.2):\n","        self.n_iter = n_iter\n","        self.frac = frac\n","\n","    def fit(self, X, Y):\n","        self.find_classes(Y)\n","        encoded_Y = self.encode_outputs(Y)\n","\n","        if not isinstance(X, np.ndarray):\n","            X = X.toarray()\n","\n","        n_instances, n_features = X.shape\n","        self.w = np.zeros(n_features)\n","        regularization = 1 / n_features\n","        \n","        t = 1\n","        n = int(n_instances*self.frac)\n","        \n","        for i in range(self.n_iter):\n","            for _ in range(n):\n","                idx = np.random.randint(0, high=n_instances)\n","                x = X[idx]\n","                y = encoded_Y[idx]\n","                t += 1\n","                learning_rate = 1 / (t * regularization)                           \n","\n","                self.w = (1 - learning_rate * regularization) * self.w\n","\n","                self.w += (y * x) / (1 + np.exp(y * (x.dot(self.w))))            \n"]},{"cell_type":"markdown","metadata":{"cell_id":"41a0b0da6e54455c967916b8398b4cc4","deepnote_cell_type":"markdown","tags":[]},"source":["## Using random batches with uniform random selection for training pairs"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"08b7eec96f09453d994bb3930efce9aa","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":7,"execution_start":1620634469578,"source_hash":"f6794c7c","tags":[]},"outputs":[],"source":["class BatchLinearSVC(LinearClassifier):\n","    def __init__(self, n_iter=20, frac=0.2):\n","        self.n_iter = n_iter\n","        self.frac = frac\n","\n","    def fit(self, X, Y):\n","        self.find_classes(Y)\n","        encoded_Y = self.encode_outputs(Y)\n","\n","        if not isinstance(X, np.ndarray):\n","            X = X.toarray()\n","\n","        n_instances, n_features = X.shape\n","        self.w = np.zeros(n_features)\n","        regularization = 1 / n_features\n","\n","        t = 1\n","        n = int(n_instances*self.frac)\n","        for i in range(self.n_iter):\n","            for _ in range(n):\n","                idx = np.random.randint(0, high=n_instances)\n","                x = X[idx]\n","                y = encoded_Y[idx]\n","                t += 1\n","                learning_rate = 1 / (t * regularization)\n","                score = x.dot(self.w)\n","\n","                self.w = (1 - learning_rate * regularization) * self.w\n","\n","                if y * score < 1:\n","                    self.w += (learning_rate * y) * x"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"348def51418f4bda8804500b9c0f90ac","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":13359,"execution_start":1620634469594,"source_hash":"1953c0de","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["BatchLinearSVC\n","Training time: 4.84 sec.\n","Accuracy: 0.8258.\n","\n","BatchLogisticRegression\n","Training time: 7.34 sec.\n","Accuracy: 0.8334.\n"]}],"source":["# Set up the preprocessing steps and the classifier.\n","# frac here is the percentage of the number of instances used in the iterations\n","pipeSVC = create_pipeline(BatchLinearSVC(frac=0.4))\n","pipeLR = create_pipeline(BatchLogisticRegression(frac=0.4))\n","\n","print(\"BatchLinearSVC\")\n","measure_pipeline(pipeSVC)\n","print(\"\\nBatchLogisticRegression\")\n","measure_pipeline(pipeLR)"]},{"cell_type":"markdown","metadata":{"cell_id":"c74876d0579542cab55d5761db11c1d5","deepnote_cell_type":"markdown","tags":[]},"source":["# Optimizing LR\n","### (a) Faster linear algebra operations\n","Here the boost functions are implemented. This saves up to around 2 seconds."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"c9f1b928b99d431ab47cbced04710e72","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":4907,"execution_start":1620634482958,"source_hash":"2c117b4d","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["LinearSVC\n","Training time: 4.41 sec.\n","Accuracy: 0.8242.\n"]}],"source":["from scipy.linalg.blas import ddot, dscal, daxpy\n","\n","# a)\n","class LinearSVC(LinearClassifier):\n","    def __init__(self, n_iter=20):\n","        self.n_iter = n_iter\n","\n","    def fit(self, X, Y):\n","        self.find_classes(Y)\n","        encoded_Y = self.encode_outputs(Y)\n","\n","        if not isinstance(X, np.ndarray):\n","            X = X.toarray()\n","\n","        n_instances, n_features = X.shape\n","        self.w = np.zeros(n_features)\n","        regularization = 1 / n_features        \n","\n","        t = 1\n","        for i in range(self.n_iter):\n","            a = 1.0\n","            for x, y in zip(X, encoded_Y):\n","                t += 1\n","                learning_rate = 1 / (t * regularization)\n","                score = ddot(x,self.w)\n","                a = 1 - learning_rate * regularization\n","                dscal(a, self.w)                \n","\n","                if y * score < 1:  \n","                    daxpy(x, self.w, a=learning_rate * y)             \n","\n","# Test optimized LR\n","pipeSVC = create_pipeline(LinearSVC())\n","print(\"LinearSVC\")\n","measure_pipeline(pipeSVC)"]},{"cell_type":"markdown","metadata":{"cell_id":"4cf82de1879b4d4eab9aa4fd55fbeeea","deepnote_cell_type":"markdown","tags":[]},"source":["### (b) Using sparse vectors\n","Here we used the sparse model used in the sparse perceptron as boilderplate and adapt it to work with LinearSVC"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"47a1f2a58bfb49cd94860cda2e3e98a3","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":7,"execution_start":1620634487879,"source_hash":"3bc45a2e","tags":[]},"outputs":[],"source":["def create_sparse_pipeline(clf, ngram_range=(1,1)):\n","    return make_pipeline(\n","        TfidfVectorizer(ngram_range=ngram_range),        \n","        Normalizer(),        \n","        clf\n","    )\n","\n","def add_sparse_to_dense(x, w, factor):   \n","    w[x.indices] += factor * x.data\n","\n","def sparse_dense_dot(x, w):\n","    return np.dot(w[x.indices], x.data)\n","\n","\n","class SparseSVC(LinearClassifier):    \n","    def __init__(self, n_iter=20):        \n","        self.n_iter = n_iter\n","\n","    def fit(self, X, Y):        \n","        self.find_classes(Y)\n","\n","        encoded_Y = self.encode_outputs(Y)\n","        n_features = X.shape[1]\n","        self.w = np.zeros(X.shape[1])    \n","        \n","        # For increased iteration speed, saves\n","        XY = list(zip(X, encoded_Y))\n","\n","        regularization = 1 / n_features    \n","        t = 1\n","        for i in range(self.n_iter):\n","            a = 1.0\n","            for x, y in XY:\n","                t += 1\n","                learning_rate = 1 / (t * regularization)\n","                score = sparse_dense_dot(x, self.w)\n","                a = 1 - learning_rate * regularization\n","                self.w *= a                \n","\n","                if y * score < 1:  \n","                    add_sparse_to_dense(x, self.w, learning_rate * y)"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"fac717f8ef4a46fab0e6a477dfbfeaf5","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":144602,"execution_start":1620634487910,"source_hash":"2c4a976","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["SparseSVC ngram_range=(1,1)\n","Training time: 13.67 sec.\n","Accuracy: 0.8334.\n","\n","SparseSVC ngram_range=(1,2)\n","Training time: 90.90 sec.\n","Accuracy: 0.8670.\n","\n","LinearSVC ngram_range=(1,1)\n","Training time: 37.61 sec.\n","Accuracy: 0.8334.\n"]}],"source":["# Test optimized LR\n","pipeSVC = create_sparse_pipeline(SparseSVC())\n","print(\"SparseSVC ngram_range=(1,1)\")\n","measure_pipeline(pipeSVC)\n","\n","pipeSVC = create_sparse_pipeline(SparseSVC(), ngram_range=(1,2))\n","print(\"\\nSparseSVC ngram_range=(1,2)\")\n","measure_pipeline(pipeSVC)\n","\n","# When ngram_range is (1,2) the normal LinearSVC crashes due to lack of ram.\n","# Meanwhile the sparse SVC takes quite a long time for large data, but it works.\n","pipeSVC = create_sparse_pipeline(LinearSVC())\n","print(\"\\nLinearSVC ngram_range=(1,1)\")\n","measure_pipeline(pipeSVC)"]},{"cell_type":"markdown","metadata":{"cell_id":"2e490a0db3224204a3ff32a3aba37773","deepnote_cell_type":"markdown","tags":[]},"source":["We can see that the sparse model is quite much faster than the standard model for ngram_range=(1,1). For ngram_range=(1,2) as mentioned, the standard model crashes due to lack of ram."]},{"cell_type":"markdown","metadata":{"cell_id":"4a6bf4a3c856416da0532ee723bc6df2","deepnote_cell_type":"markdown","tags":[]},"source":["### (c) Speeding up the scaling operation\n","\n","Here the rescaling of w is done once instead of every iteration, as shown in the clarification paper in section 2.4. This does not really matter in the normal case, but in the sparse case it save several seconds."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"e6a71ed3e9334032a9211655580f99d1","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":6212,"execution_start":1620634632514,"source_hash":"179ad357","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["LinearSVC\n","Training time: 5.62 sec.\n","Accuracy: 0.8242.\n"]}],"source":["class RescalingLinearSVC(LinearClassifier):\n","    def __init__(self, n_iter=20):\n","        self.n_iter = n_iter\n","\n","    def fit(self, X, Y):\n","        self.find_classes(Y)\n","        encoded_Y = self.encode_outputs(Y)\n","\n","        if not isinstance(X, np.ndarray):\n","            X = X.toarray()\n","\n","        n_instances, n_features = X.shape\n","        self.w = np.zeros(n_features)\n","        regularization = 1 / n_features        \n","\n","        t = 1\n","        a = 1.0\n","        for i in range(self.n_iter):            \n","            for x, y in zip(X, encoded_Y):\n","                t += 1\n","                learning_rate = 1 / (t * regularization)\n","                \n","                score = ddot(x,self.w) * a\n","                a = (1 - learning_rate * regularization) * a\n","                \n","                \n","                if y * score < 1:                    \n","                    daxpy((x*learning_rate*y), self.w, a=1/a)                    \n","\n","        dscal(a, self.w)               \n","\n","# Test optimized LR\n","pipeSVC = create_pipeline(RescalingLinearSVC())\n","print(\"LinearSVC\")\n","measure_pipeline(pipeSVC)"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"72ebd59b7ed54a2ab582fc33514742d3","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":8487,"execution_start":1620634638729,"source_hash":"e5b35184","tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["RescalingSVC\n","Training time: 7.70 sec.\n","Accuracy: 0.8334.\n"]}],"source":["class SparseRescalingSVC(LinearClassifier):    \n","    def __init__(self, n_iter=20):        \n","        self.n_iter = n_iter\n","\n","    def fit(self, X, Y):        \n","        self.find_classes(Y)\n","\n","        encoded_Y = self.encode_outputs(Y)\n","        n_features = X.shape[1]\n","        self.w = np.zeros(X.shape[1])    \n","        \n","        # For increased iteration speed, saves\n","        XY = list(zip(X, encoded_Y))\n","\n","        regularization = 1 / n_features    \n","        t = 1\n","        a = 1.0\n","        for i in range(self.n_iter):\n","            for x, y in XY:\n","                t += 1\n","                learning_rate = 1 / (t * regularization)\n","                \n","                score = sparse_dense_dot(x, self.w) * a   \n","                a = (1 - learning_rate * regularization) * a\n","\n","               \n","\n","                if y * score < 1:  \n","                    add_sparse_to_dense(x, self.w, learning_rate * y / a)\n","        self.w *= a\n","\n","\n","pipeSVC = create_sparse_pipeline(SparseRescalingSVC())\n","print(\"RescalingSVC\")\n","measure_pipeline(pipeSVC)"]}],"metadata":{"deepnote":{"is_reactive":false},"deepnote_execution_queue":[],"deepnote_notebook_id":"69ff041853a848eab99918aa7582aac9","language_info":{"name":"python"},"orig_nbformat":2},"nbformat":4,"nbformat_minor":0}
